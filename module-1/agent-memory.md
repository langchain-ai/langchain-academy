# Agent memory

## Review

以前、以下の機能を持つエージェントを構築しました：

* `act` - モデルに特定のツールを呼び出させる
* `observe` - ツールの出力をモデルに戻す 
* `reason` - モデルにツールの出力について推論させ、次に何をするか決定させる(例：別のツールを呼び出すか、直接応答するか)

## Goals

今回は、メモリを導入してエージェントを拡張します。

[以下、環境設定のコードブロックは原文のまま]

[LangSmith](https://docs.smith.langchain.com/)を[トレース](https://docs.smith.langchain.com/concepts/tracing)のために使用します。

これは以前行ったことに従います。

## Memory

前回と同じように、エージェントを実行してみましょう。

では、2を掛けてみましょう！

最初のチャットから7という記憶が保持されていません！

これは、[状態が1回のグラフ実行に一時的なもの](https://github.com/langchain-ai/langgraph/discussions/352#discussioncomment-9291220)だからです。

もちろん、これは中断を含む複数ターンの会話を行う能力を制限します。

この問題に対処するために[永続化](https://langchain-ai.github.io/langgraph/how-tos/persistence/)を使用できます！

LangGraphはチェックポインターを使用して、各ステップ後にグラフの状態を自動的に保存できます。

この組み込みの永続化層によってメモリが提供され、LangGraphが最後の状態更新から再開できるようになります。

最も簡単なチェックポインターの1つは`MemorySaver`で、これはグラフ状態用のインメモリのキーバリューストアです。

必要なのは、単にチェックポインターを使ってグラフをコンパイルするだけで、グラフにメモリが備わります！

メモリを使用する際は、`thread_id`を指定する必要があります。

この`thread_id`は、私たちのグラフ状態のコレクションを保存します。

これを図で説明すると：

* チェックポインターはグラフの各ステップで状態を書き込みます
* これらのチェックポイントはスレッドに保存されます
* 将来`thread_id`を使ってそのスレッドにアクセスできます

同じ`thread_id`を渡すと、以前にログに記録された状態チェックポイントから続行できます！

この場合、上記の会話がスレッドに記録されています。

渡す`HumanMessage`（「Multiply that by 2.」）は上記の会話に追加されます。

そのため、モデルは「that」が「The sum of 3 and 4 is 7.」を指していることを理解します。