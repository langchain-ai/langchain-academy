{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "147e576c",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-3/edit-state-human-feedback.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239520-lesson-3-editing-state-and-human-feedback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2f2448-21c3-4196-9e61-0b47e7d0048b",
   "metadata": {},
   "source": [
    "# Editing graph state\n",
    "\n",
    "## Review\n",
    "\n",
    "We discussed motivations for human-in-the-loop:\n",
    "\n",
    "(1) `Approval` - We can interrupt our agent, surface state to a user, and allow the user to accept an action\n",
    "\n",
    "(2) `Debugging` - We can rewind the graph to reproduce or avoid issues\n",
    "\n",
    "(3) `Editing` - You can modify the state \n",
    "\n",
    "We showed how breakpoints support user approval, but don't yet know how to modify our graph state once our graph is interrupted!\n",
    "\n",
    "## Goals\n",
    "\n",
    "Now, let's show how to directly edit the graph state and insert human feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95d26b8c-d958-4d21-9ca4-4636d3dfe45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph langchain_openai langgraph_sdk langchain-google-vertexai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5948594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a8df1f-a76a-4803-a532-ea9802106ac8",
   "metadata": {},
   "source": [
    "## Editing state \n",
    "\n",
    "Previously, we introduced breakpoints.\n",
    "\n",
    "We used them to interrupt the graph and await user approval before executing the next node.\n",
    "\n",
    "But breakpoints are also [opportunities to modify the graph state](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/edit-graph-state/).\n",
    "\n",
    "Let's set up our agent with a breakpoint before the `assistant` node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcf24f05-ac2b-455e-846c-0c50ac86e1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rlm/Desktop/Code/langchain-academy/lc-academy-env/lib/python3.12/site-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "# This will be a tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a / b\n",
    "\n",
    "tools = [add, multiply, divide]\n",
    "# llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm = ChatVertexAI(model=\"gemini-1.5-flash\", temperature=0)\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dfe84af-5c62-4c3f-8ed7-96b5261f0b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# System message\n",
    "sys_msg = SystemMessage(content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\")\n",
    "\n",
    "# Node\n",
    "def assistant(state: MessagesState):\n",
    "   return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Define edges: these determine the control flow\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(interrupt_before=[\"assistant\"], checkpointer=memory)\n",
    "\n",
    "# Show\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a47fd5-1f60-41dc-9206-698ed8ece530",
   "metadata": {},
   "source": [
    "Let's run!\n",
    "\n",
    "We can see the graph is interrupted before the chat model responds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2ce488d-00e4-492e-a62c-dd98702c313f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "initial_input = {\"messages\": \"Multiply 2 and 3\"}\n",
    "\n",
    "# Thread\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Run the graph until the first interruption\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4be478ef-bd60-4d32-8a05-5f56c93a8396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Multiply 2 and 3', additional_kwargs={}, response_metadata={}, id='8e29be82-8db5-46b1-bd27-eb02496ad691')]}, next=('assistant',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef7a059-7cc7-61aa-8000-95edc7fbc63e'}}, metadata={'source': 'loop', 'writes': None, 'step': 0, 'parents': {}}, created_at='2024-09-23T23:43:11.195784+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef7a059-7cc4-6266-bfff-e637397a09b3'}}, tasks=(PregelTask(id='43a14559-c878-aa92-79bc-895ca8391630', name='assistant', path=('__pregel_pull', 'assistant'), error=None, interrupts=(), state=None),))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = graph.get_state(thread)\n",
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ef63a1-2ab8-416d-babf-d35054e294f0",
   "metadata": {},
   "source": [
    "Now, we can directly apply a state update.\n",
    "\n",
    "Remember, updates to the `messages` key will use the `add_messages` reducer:\n",
    " \n",
    "* If we want to over-write the existing message, we can supply the message `id`.\n",
    "* If we simply want to append to our list of messages, then we can pass a message without an `id` specified, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9179cff1-e529-473a-9ce2-e23b932c2063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1ef7a059-9cac-62ea-8001-87db9781cd21'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.update_state(\n",
    "    thread,\n",
    "    {\"messages\": [HumanMessage(content=\"No, actually multiply 3 and 3!\")]},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77b8d6a-8c7b-4f7a-b723-121af25ac829",
   "metadata": {},
   "source": [
    "Let's have a look.\n",
    "\n",
    "We called `update_state` with a new message. \n",
    "\n",
    "The `add_messages` reducer appends it to our state key, `messages`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "141b6aab-ec6d-44f3-beb1-6c22ac5f2158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "No, actually multiply 3 and 3!\n"
     ]
    }
   ],
   "source": [
    "new_state = graph.get_state(thread).values\n",
    "for m in new_state['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4041959-cc3a-4168-8cf7-06d1711921d8",
   "metadata": {},
   "source": [
    "Now, let's proceed with our agent, simply by passing `None` and allowing it proceed from the current state.\n",
    "\n",
    "We emit the current and then proceed to execute the remaining nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f166bed2-87c9-41ec-b235-0305721c2d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "No, actually multiply 3 and 3!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rlm/Desktop/Code/langchain-academy/lc-academy-env/lib/python3.12/site-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (c0652f68-9943-476a-a8f0-c4acf80f357d)\n",
      " Call ID: c0652f68-9943-476a-a8f0-c4acf80f357d\n",
      "  Args:\n",
      "    a: 3.0\n",
      "    b: 3.0\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18dc1ca",
   "metadata": {},
   "source": [
    "Now, we're back at the `assistant`, which has our `breakpoint`.\n",
    "\n",
    "We can again pass `None` to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5952731-0170-4589-a399-ee787df35400",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised InvalidArgument: 400 Please ensure that function call turn comes immediately after a user turn or after a function response turn..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised InvalidArgument: 400 Please ensure that function call turn comes immediately after a user turn or after a function response turn..\n",
      "Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised InvalidArgument: 400 Please ensure that function call turn comes immediately after a user turn or after a function response turn..\n",
      "Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 8.0 seconds as it raised InvalidArgument: 400 Please ensure that function call turn comes immediately after a user turn or after a function response turn..\n",
      "Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 10.0 seconds as it raised InvalidArgument: 400 Please ensure that function call turn comes immediately after a user turn or after a function response turn..\n"
     ]
    },
    {
     "ename": "InvalidArgument",
     "evalue": "400 Please ensure that function call turn comes immediately after a user turn or after a function response turn.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/Code/langchain-academy/lc-academy-env/lib/python3.12/site-packages/google/api_core/grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Desktop/Code/langchain-academy/lc-academy-env/lib/python3.12/site-packages/grpc/_channel.py:1181\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1175\u001b[0m (\n\u001b[1;32m   1176\u001b[0m     state,\n\u001b[1;32m   1177\u001b[0m     call,\n\u001b[1;32m   1178\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[1;32m   1179\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[1;32m   1180\u001b[0m )\n\u001b[0;32m-> 1181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Code/langchain-academy/lc-academy-env/lib/python3.12/site-packages/grpc/_channel.py:1006\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1006\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.INVALID_ARGUMENT\n\tdetails = \"Please ensure that function call turn comes immediately after a user turn or after a function response turn.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:142.250.191.42:443 {created_time:\"2024-09-23T16:43:54.309151-07:00\", grpc_status:3, grpc_message:\"Please ensure that function call turn comes immediately after a user turn or after a function response turn.\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretty_print\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Code/langchain-academy/lc-academy-env/lib/python3.12/site-packages/langgraph/pregel/__init__.py:1278\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   1268\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[1;32m   1269\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   1271\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[1;32m   1272\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   1273\u001b[0m         input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels,\n\u001b[1;32m   1274\u001b[0m         interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before_,\n\u001b[1;32m   1275\u001b[0m         interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after_,\n\u001b[1;32m   1276\u001b[0m         manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[1;32m   1277\u001b[0m     ):\n\u001b[0;32m-> 1278\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1280\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1281\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1282\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[1;32m   1285\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Code/langchain-academy/lc-academy-env/lib/python3.12/site-packages/langgraph/pregel/runner.py:56\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m     54\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 56\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Desktop/Code/langchain-academy/lc-academy-env/lib/python3.12/site-packages/langgraph/pregel/retry.py:29\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy)\u001b[0m\n\u001b[1;32m     27\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Code/langchain-academy/lc-academy-env/lib/python3.12/site-packages/langgraph/utils/runnable.py:385\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 385\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/Desktop/Code/langchain-academy/lc-academy-env/lib/python3.12/site-packages/langgraph/utils/runnable.py:167\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    166\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m--> 167\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[3], line 15\u001b[0m, in \u001b[0;36massistant\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21massistant\u001b[39m(state: MessagesState):\n\u001b[0;32m---> 15\u001b[0m    \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[43mllm_with_tools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msys_msg\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m]}\n",
      "File \u001b[0;32m~/Desktop/Code/langchain-academy/lc-academy-env/lib/python3.12/site-packages/langchain_core/runnables/base.py:5343\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m   5338\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5339\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   5340\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   5341\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   5342\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m-> 5343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5344\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5345\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5346\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5347\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Code/langchain-academy/lc-academy-env/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:284\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    280\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    281\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    283\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 284\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    294\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/Desktop/Code/langchain-academy/lc-academy-env/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:784\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    778\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    782\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    783\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Code/langchain-academy/lc-academy-env/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:641\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    640\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 641\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    642\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    643\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[1;32m    644\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    645\u001b[0m ]\n\u001b[1;32m    646\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/Desktop/Code/langchain-academy/lc-academy-env/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:631\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    630\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 631\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m         )\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    639\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/Desktop/Code/langchain-academy/lc-academy-env/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:853\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 853\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    857\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Desktop/Code/langchain-academy/lc-academy-env/lib/python3.12/site-packages/langchain_google_vertexai/chat_models.py:1170\u001b[0m, in \u001b[0;36mChatVertexAI._generate\u001b[0;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_gemini_model:\n\u001b[1;32m   1169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_non_gemini(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_gemini\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_gemini\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Code/langchain-academy/lc-academy-env/lib/python3.12/site-packages/langchain_google_vertexai/chat_models.py:1327\u001b[0m, in \u001b[0;36mChatVertexAI._generate_gemini\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_gemini\u001b[39m(\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1321\u001b[0m     messages: List[BaseMessage],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1324\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1325\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[1;32m   1326\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request_gemini(messages\u001b[38;5;241m=\u001b[39mmessages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1327\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_completion_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1333\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gemini_response_to_chat_result(response)\n",
      "File \u001b[0;32m~/Desktop/Code/langchain-academy/lc-academy-env/lib/python3.12/site-packages/langchain_google_vertexai/chat_models.py:608\u001b[0m, in \u001b[0;36m_completion_with_retry\u001b[0;34m(generation_method, max_retries, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generation_method(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    603\u001b[0m params \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    604\u001b[0m     {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m _allowed_params_prediction_service}\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_gemini\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    606\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m kwargs\n\u001b[1;32m    607\u001b[0m )\n\u001b[0;32m--> 608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_completion_with_retry_inner\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Code/langchain-academy/lc-academy-env/lib/python3.12/site-packages/tenacity/__init__.py:336\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    334\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    335\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Code/langchain-academy/lc-academy-env/lib/python3.12/site-packages/tenacity/__init__.py:475\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 475\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/Code/langchain-academy/lc-academy-env/lib/python3.12/site-packages/tenacity/__init__.py:376\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    374\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 376\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Desktop/Code/langchain-academy/lc-academy-env/lib/python3.12/site-packages/tenacity/__init__.py:418\u001b[0m, in \u001b[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    416\u001b[0m retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[0;32m--> 418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n",
      "File \u001b[0;32m~/Desktop/Code/langchain-academy/lc-academy-env/lib/python3.12/site-packages/tenacity/__init__.py:185\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[0;32m--> 185\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Code/langchain-academy/lc-academy-env/lib/python3.12/site-packages/tenacity/__init__.py:478\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 478\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    480\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Code/langchain-academy/lc-academy-env/lib/python3.12/site-packages/langchain_google_vertexai/chat_models.py:601\u001b[0m, in \u001b[0;36m_completion_with_retry.<locals>._completion_with_retry_inner\u001b[0;34m(generation_method, **kwargs)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry_inner\u001b[39m(generation_method: Callable, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 601\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeneration_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Code/langchain-academy/lc-academy-env/lib/python3.12/site-packages/google/cloud/aiplatform_v1beta1/services/prediction_service/client.py:2275\u001b[0m, in \u001b[0;36mPredictionServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   2272\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m   2274\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m-> 2275\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2280\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2282\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m   2283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Desktop/Code/langchain-academy/lc-academy-env/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Code/langchain-academy/lc-academy-env/lib/python3.12/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgument\u001b[0m: 400 Please ensure that function call turn comes immediately after a user turn or after a function response turn."
     ]
    }
   ],
   "source": [
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc22c3e9-b00c-4ead-b752-a682b45b3718",
   "metadata": {},
   "source": [
    "### Editing graph state in Studio\n",
    "\n",
    "--\n",
    "\n",
    "** DISCLAIMER**\n",
    "\n",
    "*Running Studio currently requires a Mac. If you are not using a Mac, then skip this step.*\n",
    "\n",
    "*Also, if you are running this notebook in CoLab, then skip this step.*\n",
    "\n",
    "--\n",
    "\n",
    "Let's load our `agent` in the Studio UI, which uses `module-3/studio/agent.py` set in `module-3/studio/langgraph.json`.\n",
    "\n",
    "### Editing graph state with LangGraph API\n",
    "\n",
    "We can interact with our agent via the SDK.\n",
    "\n",
    "![Screenshot 2024-08-26 at 9.59.19 AM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbaf2fbfb576f8e53ed930_edit-state-human-feedback1.png)\n",
    "\n",
    "Let's get the URL for the local deployment from Studio.\n",
    "\n",
    "The LangGraph API [supports editing graph state](https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_edit_state/#initial-invocation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "642aabab-f822-4917-9d66-3314ac5008fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_sdk import get_client\n",
    "client = get_client(url=\"http://localhost:56091\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be74cb09",
   "metadata": {},
   "source": [
    "Our agent is defined in `assistant/agent.py`. \n",
    "\n",
    "If you look at the code, you'll see that it *does not* have a breakpoint! \n",
    " \n",
    "Of course, we can add it to `agent.py`, but one very nice feature of the API is that we can pass in a breakpoint!\n",
    "\n",
    "Here, we pass a `interrupt_before=[\"assistant\"]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c352f9e-6a0f-4a94-a083-b85b0233efa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receiving new event of type: metadata...\n",
      "--------------------------------------------------\n",
      "Receiving new event of type: values...\n",
      "{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '882dabe4-b877-4d71-bd09-c34cb97c4f46', 'example': False}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "initial_input = {\"messages\": \"Multiply 2 and 3\"}\n",
    "thread = await client.threads.create()\n",
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    \"agent\",\n",
    "    input=initial_input,\n",
    "    stream_mode=\"values\",\n",
    "    interrupt_before=[\"assistant\"],\n",
    "):\n",
    "    print(f\"Receiving new event of type: {chunk.event}...\")\n",
    "    messages = chunk.data.get('messages', [])\n",
    "    if messages:\n",
    "        print(messages[-1])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13065dd9-5f43-47d6-ac2a-9dc15c0c54e6",
   "metadata": {},
   "source": [
    "We can get the current state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4da2c464-3e71-496a-badc-671aeee168b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'values': {'messages': [{'content': 'Multiply 2 and 3',\n",
       "    'additional_kwargs': {},\n",
       "    'response_metadata': {},\n",
       "    'type': 'human',\n",
       "    'name': None,\n",
       "    'id': '882dabe4-b877-4d71-bd09-c34cb97c4f46',\n",
       "    'example': False}]},\n",
       " 'next': ['assistant'],\n",
       " 'tasks': [{'id': 'a71c0b80-a679-57cb-aa59-a1655b763480',\n",
       "   'name': 'assistant',\n",
       "   'error': None,\n",
       "   'interrupts': [],\n",
       "   'state': None}],\n",
       " 'metadata': {'step': 0,\n",
       "  'run_id': '1ef6a41c-ea63-663f-b3e8-4f001bf0bf53',\n",
       "  'source': 'loop',\n",
       "  'writes': None,\n",
       "  'parents': {},\n",
       "  'user_id': '',\n",
       "  'graph_id': 'agent',\n",
       "  'thread_id': 'a95ffa54-2435-4a47-a9da-e886369ca8ee',\n",
       "  'created_by': 'system',\n",
       "  'assistant_id': 'fe096781-5601-53d2-b2f6-0d3403f7e9ca'},\n",
       " 'created_at': '2024-09-03T22:13:54.466695+00:00',\n",
       " 'checkpoint_id': '1ef6a41c-ead7-637b-8000-8c6a7b98379e',\n",
       " 'parent_checkpoint_id': '1ef6a41c-ead3-637d-bfff-397ebdb4f2ea'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_state = await client.threads.get_state(thread['thread_id'])\n",
    "current_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4527bbf1-0927-41a6-aeef-d15e32bbbdc3",
   "metadata": {},
   "source": [
    "We can look at the last message in state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "801ae2d9-0551-46b8-aee2-82293cee4011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'Multiply 2 and 3',\n",
       " 'additional_kwargs': {},\n",
       " 'response_metadata': {},\n",
       " 'type': 'human',\n",
       " 'name': None,\n",
       " 'id': '882dabe4-b877-4d71-bd09-c34cb97c4f46',\n",
       " 'example': False}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_message = current_state['values']['messages'][-1]\n",
    "last_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0581ba8-db3d-474d-9042-b1c7f3461caf",
   "metadata": {},
   "source": [
    "We can edit it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86b12be7-7e4a-40d0-8521-dced7c393c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'No, actually multiply 3 and 3!',\n",
       " 'additional_kwargs': {},\n",
       " 'response_metadata': {},\n",
       " 'type': 'human',\n",
       " 'name': None,\n",
       " 'id': '882dabe4-b877-4d71-bd09-c34cb97c4f46',\n",
       " 'example': False}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_message['content'] = \"No, actually multiply 3 and 3!\"\n",
    "last_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f84f2c24-f281-4591-90e5-de3a5547c9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'No, actually multiply 3 and 3!',\n",
       " 'additional_kwargs': {},\n",
       " 'response_metadata': {},\n",
       " 'type': 'human',\n",
       " 'name': None,\n",
       " 'id': '882dabe4-b877-4d71-bd09-c34cb97c4f46',\n",
       " 'example': False}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7b4280-6ae7-4246-9c87-44e0daa6c654",
   "metadata": {},
   "source": [
    "Remember, as we said before, updates to the `messages` key will use the same `add_messages` reducer. \n",
    "\n",
    "If we want to over-write the existing message, then we can supply the message `id`.\n",
    "\n",
    "Here, we did that. We only modified the message `content`, as shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84d33b6e-32ff-4eca-8114-345e508f3481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': 'a95ffa54-2435-4a47-a9da-e886369ca8ee',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1ef6a41d-cc8e-6979-8001-8c7c283b636c'},\n",
       " 'checkpoint_id': '1ef6a41d-cc8e-6979-8001-8c7c283b636c'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await client.threads.update_state(thread['thread_id'], {\"messages\": last_message})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f07f0d1-7083-4827-babd-d3702eb59a37",
   "metadata": {},
   "source": [
    "Now, we resume by passing `None`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef18d12d-e0a6-487a-9f32-ad30e2634a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receiving new event of type: metadata...\n",
      "--------------------------------------------------\n",
      "Receiving new event of type: values...\n",
      "{'content': 'No, actually multiply 3 and 3!', 'additional_kwargs': {'additional_kwargs': {}, 'response_metadata': {}, 'example': False}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '882dabe4-b877-4d71-bd09-c34cb97c4f46', 'example': False}\n",
      "--------------------------------------------------\n",
      "Receiving new event of type: values...\n",
      "{'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_vi16je2EIikHuT7Aue2sd1qd', 'function': {'arguments': '{\"a\":3,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'type': 'ai', 'name': None, 'id': 'run-775b42f7-0590-4c54-aaeb-78599b1f12d2', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 3, 'b': 3}, 'id': 'call_vi16je2EIikHuT7Aue2sd1qd', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}\n",
      "--------------------------------------------------\n",
      "Receiving new event of type: values...\n",
      "{'content': '9', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '226bfbad-0cea-4900-80c5-761a62bd4bc1', 'tool_call_id': 'call_vi16je2EIikHuT7Aue2sd1qd', 'artifact': None, 'status': 'success'}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"agent\",\n",
    "    input=None,\n",
    "    stream_mode=\"values\",\n",
    "    interrupt_before=[\"assistant\"],\n",
    "):\n",
    "    print(f\"Receiving new event of type: {chunk.event}...\")\n",
    "    messages = chunk.data.get('messages', [])\n",
    "    if messages:\n",
    "        print(messages[-1])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a82dd35-cbc8-486d-8e20-10d0c4d138d6",
   "metadata": {},
   "source": [
    "We get the result of the tool call as `9`, as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d1bb3c7-dc26-4c32-b3df-865f41ef3c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receiving new event of type: metadata...\n",
      "--------------------------------------------------\n",
      "Receiving new event of type: values...\n",
      "{'content': '9', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '226bfbad-0cea-4900-80c5-761a62bd4bc1', 'tool_call_id': 'call_vi16je2EIikHuT7Aue2sd1qd', 'artifact': None, 'status': 'success'}\n",
      "--------------------------------------------------\n",
      "Receiving new event of type: values...\n",
      "{'content': 'The result of multiplying 3 by 3 is 9.', 'additional_kwargs': {}, 'response_metadata': {'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'type': 'ai', 'name': None, 'id': 'run-859bbf47-9f35-4e71-ae98-9d93ee49d16c', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"agent\",\n",
    "    input=None,\n",
    "    stream_mode=\"values\",\n",
    "    interrupt_before=[\"assistant\"],\n",
    "):\n",
    "    print(f\"Receiving new event of type: {chunk.event}...\")\n",
    "    messages = chunk.data.get('messages', [])\n",
    "    if messages:\n",
    "        print(messages[-1])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6914c5ca-27e4-421c-835a-9e4327dac12f",
   "metadata": {},
   "source": [
    "## Awaiting user input\n",
    "\n",
    "So, it's clear that we can edit our agent state after a breakpoint.\n",
    "\n",
    "Now, what if we want to allow for human feedback to perform this state update?\n",
    "\n",
    "We'll add a node that [serves as a placeholder for human feedback](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/wait-user-input/#setup) within our agent.\n",
    "\n",
    "This `human_feedback` node allow the user to add feedback directly to state.\n",
    " \n",
    "We specify the breakpoint using `interrupt_before` our `human_feedback` node.\n",
    "\n",
    "We set up a checkpointer to save the state of the graph up until this node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4b475ff-681f-4660-80dd-d6ade7bd48e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# System message\n",
    "sys_msg = SystemMessage(content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\")\n",
    "\n",
    "# no-op node that should be interrupted on\n",
    "def human_feedback(state: MessagesState):\n",
    "    pass\n",
    "\n",
    "# Assistant node\n",
    "def assistant(state: MessagesState):\n",
    "   return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "builder.add_node(\"human_feedback\", human_feedback)\n",
    "\n",
    "# Define edges: these determine the control flow\n",
    "builder.add_edge(START, \"human_feedback\")\n",
    "builder.add_edge(\"human_feedback\", \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"human_feedback\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(interrupt_before=[\"human_feedback\"], checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d4ceb6-a224-4307-8196-3f53d367df5c",
   "metadata": {},
   "source": [
    "We will get feedback from the user.\n",
    "\n",
    "We use `.update_state` to update the state of the graph with the human response we get, as before.\n",
    "\n",
    "We use the `as_node=\"human_feedback\"` parameter to apply this state update as the specified node, `human_feedback`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fc7bcd6-660c-4a8a-ad8d-e6698dcf6201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "no, multiply 3 and 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_sewrDyCrAJBQQecusUoT6OJ6)\n",
      " Call ID: call_sewrDyCrAJBQQecusUoT6OJ6\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 3\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "initial_input = {\"messages\": \"Multiply 2 and 3\"}\n",
    "\n",
    "# Thread\n",
    "thread = {\"configurable\": {\"thread_id\": \"5\"}}\n",
    "\n",
    "# Run the graph until the first interruption\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "    \n",
    "# Get user input\n",
    "user_input = input(\"Tell me how you want to update the state: \")\n",
    "\n",
    "# We now update the state as if we are the human_feedback node\n",
    "graph.update_state(thread, {\"messages\": user_input}, as_node=\"human_feedback\")\n",
    "\n",
    "# Continue the graph execution\n",
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abf4cf5f-c0cb-4fdb-be6b-271ae4e967e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "9\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of multiplying 3 and 3 is 9.\n"
     ]
    }
   ],
   "source": [
    "# Continue the graph execution\n",
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
