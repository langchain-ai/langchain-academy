# Chatbot with message summarization

## Review

graph state schemaとreducerのカスタマイズ方法について学んできました。

また、graph stateでメッセージをトリミングやフィルタリングする様々な方法も見てきました。

## Goals

さらに一歩進んでみましょう!

メッセージの単なるトリミングやフィルタリングではなく、LLMを使って会話の継続的な要約を生成する方法を紹介します。

これにより、トリミングやフィルタリングで会話を削除するのではなく、会話全体の圧縮された表現を保持することができます。

この要約機能をシンプルなチャットボットに組み込みます。

そしてそのチャットボットにメモリを装備し、高いトークンコストやレイテンシーを発生させることなく、長時間の会話をサポートできるようにします。

## Messages as state

前回同様に`MessagesState`を使用します。

組み込みの`messages`キーに加えて、今回はカスタムキー(`summary`)を追加します。

[コード例]

要約が存在する場合はそれをプロンプトに組み込むLLMを呼び出すノードを定義します。

[コード例] 

要約を生成するノードを定義します。

ここで注意すべきは、要約を生成した後に`RemoveMessage`を使用して状態をフィルタリングすることです。

[コード例]

会話の長さに基づいて要約を生成するかどうかを判断する条件付きエッジを追加します。

## Adding memory 

[state is transient](https://github.com/langchain-ai/langgraph/discussions/352#discussioncomment-9291220)を思い出してください。

これは中断のある複数のターンの会話を持つ能力を制限します。

モジュール1の最後で紹介したように、これに対処するために[persistence](https://langchain-ai.github.io/langgraph/how-tos/persistence/)を使用できます!

LangGraphは各ステップ後にgraph stateを自動的に保存するチェックポインターを使用できます。

この組み込みの永続化レイヤーによってメモリが提供され、LangGraphは最後の状態更新から再開できます。

以前示したように、最も扱いやすいのは`MemorySaver`で、これはgraph state用のインメモリキーバリューストアです。

チェックポインターを使用してグラフをコンパイルするだけで、グラフにメモリが確保されます。

## Threads

チェックポインターは各ステップで状態をチェックポイントとして保存します。

これらの保存されたチェックポイントは会話の「スレッド」にグループ化できます。

Slackを例に考えてみましょう:異なるチャンネルで異なる会話が行われています。

スレッドはSlackチャンネルのようなもので、状態(例:会話)のグループ化されたコレクションを捕捉します。

以下では、`configurable`を使用してスレッドIDを設定します。

[図の説明]

現時点では、メッセージが 6 件未満であるため、状態の概要はまだありません。

これは `should_continue` で設定されています。

```
# メッセージが 6 件を超える場合は、会話を要約します
if len(messages) > 6:
return "summarize_conversation"
```

スレッドがあるため、会話をピックアップできます。

スレッド ID 付きの `config` を使用すると、以前にログに記録された状態から続行できます。
